{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3afb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(project_root)\n",
    "pd.set_option('display.max_columns', 100)  # or however many you want\n",
    "pd.set_option('display.max_rows', 200)\n",
    "print(\"Project root:\", project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9718c973",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"500ktest_dataset_lar.csv\"\n",
    "script_dir = os.path.dirname('__file__')\n",
    "data_path = os.path.join(script_dir, '..', 'datasets', filename)\n",
    "data_path = os.path.abspath(data_path)\n",
    "df=pd.read_csv(data_path)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafafb20",
   "metadata": {},
   "source": [
    "## TabNet training NN on Test Dataset\n",
    "\n",
    "Ouput should be an action_taken label from the options below:\n",
    "\n",
    "| Code | Description                                      |\n",
    "|:----:|:-------------------------------------------------|\n",
    "| 1    | Loan originated                                  |\n",
    "| 2    | Application approved but not accepted            |\n",
    "| 3    | Application denied                               |\n",
    "| 4    | Application withdrawn by applicant               |\n",
    "| 5    | File closed for incompleteness                   |\n",
    "| 6    | Purchased loan                                   |\n",
    "| 7    | Preapproval request denied                       |\n",
    "| 8    | Preapproval request approved but not accepted    |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80049255",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c704d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "target='action_taken'\n",
    "print(\"Number of NaNs:\", df[target].isna().sum())\n",
    "print(f\"Target distribution:\\n{df[target].value_counts().sort_index()}\")\n",
    "print(\"First, we are going to drop all the columns where action_taken={4, 5, 6, 7, 8}. \")\n",
    "df = df[~df[\"action_taken\"].isin([4,5,6,7,8])].copy()\n",
    "print(f\"This leaves us with {len(df)} rows\")\n",
    "#Next we combine categories 1 and 2 because they both indicate the loan was approved.\n",
    "print(\"Combining categories 1 and 2 because they both indicate loan approval\")\n",
    "df['action_taken']=df['action_taken'].isin([1,2]).astype(int)\n",
    "print(f\"Binary target distribution:\\n{df[target].value_counts().sort_index()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47454bb",
   "metadata": {},
   "source": [
    "## Unused/Optional Features\n",
    "1. Census features are optional because they are appended to the public HMDA data after collection, and thus are not used in initial loan approval\n",
    "2. Irrelevant features are dropped because they consist of categories such as AUS1 (the automated underwriting system(s) (AUS) used by the financial institution to evaluate the application) which ideally should have no impact on an application because they are not borrower statistics. Other lender choice features also include credit score type, which the borrower does not know. \n",
    "3. Data Leakage features contain information that is only available after loan approval. For example, the 'intro_rate_period' which only exists when the loan reaches the underwriting stage, or 'denial_reason_1' which only exists when applications are denied. However, these might be good for explainability reasons in post-training.\n",
    "4. Demographic features are protected features such as sex, race and age. These features are removed from the model to ensure compliance with regulations ('Equal Credit Opportunity Act') which prevent them from being used in a credit decision. However, we acknowledging that this demographic-blind approach may still leave residual bias, which is beyond the scope of this project in interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f925d61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_process\n",
    "census_features=['tract_population', 'tract_minority_population_percent',\n",
    "       'ffiec_msa_md_median_family_income', 'tract_to_msa_income_percentage',\n",
    "       'tract_owner_occupied_units', 'tract_one_to_four_family_homes',\n",
    "       'tract_median_age_of_housing_units']\n",
    "irrelevant_feat = ['aus_1','submission_of_application', 'Unnamed: 0', 'activity_year', 'applicant_credit_score_type', 'co_applicant_credit_score_type']\n",
    "leakage_feat=[\"denial_reason_1\", \"interest_rate\",       \n",
    "    \"total_loan_costs\",   \n",
    "    \"origination_charges\", \n",
    "    \"discount_points\",     \n",
    "    \"lender_credits\",       \n",
    "    'rate_spread', 'hoepa_status', 'purchaser_type']\n",
    "protected_feat=['derived_ethnicity', 'derived_race', 'derived_sex', 'applicant_ethnicity_1',\n",
    "       'co_applicant_ethnicity_1', 'applicant_ethnicity_observed',\n",
    "       'co_applicant_ethnicity_observed', 'applicant_race_1',\n",
    "       'co_applicant_race_1', 'applicant_race_observed',\n",
    "       'co_applicant_race_observed', 'applicant_sex', 'co_applicant_sex',\n",
    "       'applicant_sex_observed', 'co_applicant_sex_observed', 'applicant_age',\n",
    "       'co_applicant_age', 'applicant_age_above_62',\n",
    "       'co_applicant_age_above_62']\n",
    "\n",
    "\n",
    "feature='denial_reason_1' #Example of data leakage\n",
    "missing=df.groupby(target)[feature].apply(lambda x: (x==10).sum())\n",
    "total_summary = df.groupby(target)[feature].size()\n",
    "percentage=missing/total_summary\n",
    "print(f\"Percentage of missing values of {feature} per action_taken:\\n\", percentage)\n",
    "#print(\"Number of NaNs:\", df[feature].isna().sum())\n",
    "#print(df[feature].value_counts().head(5))\n",
    "print(\"We can see that denial reason almost always takes the value of 10 when the action_taken=1: loan is approved. This is data leakage.\\n\")\n",
    "\n",
    "feature='rate_spread' #Example of data leakage\n",
    "missing=df.groupby(target)[feature].apply(lambda x: x.isna().sum())\n",
    "total_summary = df.groupby(target)[feature].size()\n",
    "percentage=missing/total_summary\n",
    "print(f\"Percentage of missing values of {feature} per action_taken:\\n\", percentage)\n",
    "#print(\"Number of NaNs:\", df[feature].isna().sum())\n",
    "#print(df[feature].value_counts().head(5))\n",
    "print(\"We can see that the rate_spread is always exempt when the action_taken=0: loan is denied.\\n\")\n",
    "\n",
    "feature='lender_credits'\n",
    "missing=df.groupby(target)[feature].apply(lambda x: x.isna().sum())\n",
    "total_summary = df.groupby(target)[feature].size()\n",
    "percentage=missing/total_summary\n",
    "print(f\"Percentage of missing values of {feature} per action_taken:\\n\", percentage)\n",
    "print(\"Number of NaNs:\", df[feature].isna().sum())\n",
    "print(df[feature].value_counts().head(5), \"\\n\")\n",
    "\n",
    "\n",
    "feature='purchaser_type'\n",
    "missing=df.groupby(target)[feature].apply(lambda x: (x==0).sum())\n",
    "total_summary = df.groupby(target)[feature].size()\n",
    "percentage=missing/total_summary\n",
    "print(f\"Percentage of missing values of {feature} per action_taken:\\n\", percentage)\n",
    "print(\"Number of NaNs:\", df[feature].isna().sum())\n",
    "print(df[feature].value_counts().head(5), \"\\n\")\n",
    "\n",
    "\n",
    "feature='interest_rate'\n",
    "missing=df.groupby(target)[feature].apply(lambda x: x.isna().sum())\n",
    "total_summary = df.groupby(target)[feature].size()\n",
    "percentage=missing/total_summary\n",
    "print(f\"Percentage of missing values of {feature} per action_taken:\\n\", percentage)\n",
    "print(\"Number of NaNs:\", df[feature].isna().sum())\n",
    "print(df[feature].value_counts().head(5), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd98970",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the above features\n",
    "todrop=census_features+irrelevant_feat+leakage_feat+protected_feat\n",
    "df_cleaned=df.drop(columns=todrop)\n",
    "df_cleaned.head(20)\n",
    "print(f\"There are now {len(df_cleaned.columns)} features for prediction in this cleaned dataset.\")\n",
    "print(df_cleaned.columns)\n",
    "print(f\"Each feature in this list is manually examined and sorted into categories outlined in the next section before encoding. We also discovered existence of mixed data types in various columns that are dealt with via feature engineering.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1bb4ba",
   "metadata": {},
   "source": [
    "## Note on Exempt and NaN datapoints:\n",
    "\n",
    "This dataset contains a number of values labeled as “Exempt”, which occur because financial institutions are permitted to withhold certain information. These exempt values can be treated as NaN for analysis purposes.\n",
    "\n",
    "Other NaN or not applicable datapoints may arise either because the information was not provided or because it does not apply to that particular loan category. For example, fixed-rate mortgages do not have an introductory rate period, so missing values in this field are expected.\n",
    "\n",
    "In some categorical variables, missing or not applicable values may also be encoded as special codes, such as 1111 or 9999. Handling of these cases is described on a case-by-case basis in the following section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830e2a21",
   "metadata": {},
   "source": [
    "## Case1.1: Low Dimensional Categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174c0880",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_dim_cat=['occupancy_type', 'manufactured_home_land_property_interest', 'manufactured_home_secured_property_type', 'conforming_loan_limit', 'derived_loan_product_type', 'derived_dwelling_category', 'loan_type', 'loan_purpose', 'lien_status', 'initially_payable_to_institution']\n",
    "\n",
    "#ToDrop:\n",
    "todrop_redundant=[]\n",
    "counts = df_cleaned.groupby(['loan_type', 'lien_status'])['derived_loan_product_type'].nunique()\n",
    "print(\"The derived loan product type is described as a join of loan type and lien status. This graph verifies that it is fully determined by the other 2 variables, so we can drop the the derived_loan_product_type variable.\")\n",
    "print(counts)\n",
    "todrop_redundant.append('derived_loan_product_type')\n",
    "\n",
    "counts = df_cleaned.groupby(['construction_method', 'total_units'])['derived_dwelling_category'].nunique()\n",
    "print(\"\\nThe derived_dwelling_category is also a join from the Construction Method and Total Units fields.\")\n",
    "print(counts)\n",
    "todrop_redundant.append('derived_dwelling_category')\n",
    "\n",
    "df_cleaned=df_cleaned.drop(columns=todrop_redundant)\n",
    "low_dim_cat=[j for j in low_dim_cat if j not in todrop_redundant]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e93b639",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_cleaned[low_dim_cat].isna().sum(), '\\n')\n",
    "for j in low_dim_cat:\n",
    "    print(\"Column data type:\", df_cleaned[j].dtype)\n",
    "    print(df_cleaned[j].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff11aa76",
   "metadata": {},
   "source": [
    "A cursory examination of the data ranges shows us that all columns are already in consistent data types. Since tabnet takes either integers or strings for categoricals. Cross-checking against data schema, we will leave the Exempt entries, encoded as 1111 in hopes tabnet can pick up these values. We will also convert the np.nan and U entries into 1111 as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e608a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "replace_map = {\n",
    "    'conforming_loan_limit': {np.nan: 1111,\n",
    "                              'C': 1,\n",
    "                              'NC': 0,\n",
    "                              'U': 1111}\n",
    "}\n",
    "df_cleaned=df_cleaned.replace(replace_map, inplace=False)\n",
    "for j in low_dim_cat:\n",
    "    df_cleaned[j]=df_cleaned[j].astype(int)\n",
    "    print(\"Column data type:\", df_cleaned[j].dtype)\n",
    "    print(df_cleaned[j].value_counts())\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ebdc65",
   "metadata": {},
   "source": [
    "## Case 1.2: Categoricals Features with High Dimension\n",
    "This is basic categorical data that requires usage of embeddings due to high dimensionality. The embedding is naturally dealt with by tabnet by passing as integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07a3048",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_dim_cat=['lei', 'derived_msa_md', 'census_tract', 'county_code', 'state_code']\n",
    "feature=high_dim_cat[1]\n",
    "for feature in high_dim_cat:\n",
    "    print(df_cleaned[feature].value_counts().head(5))\n",
    "    print(\"Column data type:\", df_cleaned[feature].dtype)\n",
    "    print(\"Number of NaNs:\", df_cleaned[feature].isna().sum())\n",
    "    print(\"Number of Exempt:\", (df_cleaned[feature]=='Exempt').sum())\n",
    "    print(f\"Number of dimensions: {len(df_cleaned[feature].value_counts())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7907b86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals=high_dim_cat+low_dim_cat\n",
    "print(len(categoricals))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76eaa864",
   "metadata": {},
   "source": [
    "## Case 2.1: Continuous Data\n",
    "This is basic continuous numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ecb373",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_to_numeric=['income', 'loan_amount']\n",
    "for feature in pd_to_numeric:\n",
    "    df_cleaned[feature]=df_cleaned[feature].astype(np.float32)\n",
    "    print(f\"Feature: {feature}\")\n",
    "    print(\"Data type: \", df_cleaned[feature].dtype)\n",
    "    print(\"Number of NaNs:\", df_cleaned[feature].isna().sum())\n",
    "    print(df_cleaned[feature].value_counts().head(10))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59bf782",
   "metadata": {},
   "source": [
    "## Case 2.2: Continuous Data with exempt:\n",
    "Exempt data in this category are treated as missing categories and can be converted to NANs functionally speaking. This is because data vizualisation has shown us the distribution of nans and exempts are distributed evenly across the various target classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43349120",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_with_exempt_numeric_to_process=['intro_rate_period', 'combined_loan_to_value_ratio', 'property_value', 'loan_term']\n",
    "for feature in cols_with_exempt_numeric_to_process:\n",
    "    df_cleaned[feature]=df_cleaned[feature].replace({'Exempt': np.nan})\n",
    "    df_cleaned[feature]=df_cleaned[feature].astype(np.float32)\n",
    "    print(\"Number of NaNs:\", df_cleaned[feature].isna().sum())\n",
    "    print(df_cleaned[feature].value_counts().head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b782e19a",
   "metadata": {},
   "source": [
    "## Case 2.3: Continuous With Range:\n",
    "These are features that are a hybrid of numerical values and numerical ranges. When there are small ranges, we replace with midpoint. When they are extremal ranges, we replace with the extremal endpoints. Rows that already contain a direct numeric value are left unchanged, preserving the available precision.\n",
    "\n",
    "This approach is motivated by the observation that lender decisions appear to require greater granularity within certain ranges, such as the 36–50 range for debt-to-income ratio. For other ranges, such as 20–30 or 30–36, grouping values into a single representative number is reasonable, as the decision process likely treats applicants within these ranges similarly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c3ecd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "numericwithranges=['debt_to_income_ratio', 'total_units']\n",
    "for feature in numericwithranges:\n",
    "    print(\"Number of NaNs:\", df_cleaned[feature].isna().sum())\n",
    "    print(df_cleaned[feature].value_counts().head(20))\n",
    "replace_map={'debt_to_income_ratio': {'30%-<36%': 33,\n",
    "                                      '20%-<30%': 25,\n",
    "                                      \"50%-60%\": 55, \n",
    "                                      '>60%': 80, \n",
    "                                      '<20%': 10, \n",
    "                                      'Exempt': np.nan},\n",
    "            'total_units': {'5-24': 29/2,\n",
    "                            '25-49': (25+49)/2,\n",
    "                            '50-99': (50+99)/2,\n",
    "                            '100-149': (100+149)/2,\n",
    "                            '>149': 200, \n",
    "                            }\n",
    "}\n",
    "#\n",
    "df_cleaned=df_cleaned.replace(replace_map, inplace=False)\n",
    "for col in numericwithranges:\n",
    "    df_cleaned[col]=df_cleaned[col].astype(np.float32)\n",
    "    print(df_cleaned[col].value_counts().head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e62c29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric=pd_to_numeric+numericwithranges+cols_with_exempt_numeric_to_process\n",
    "print(len(numeric))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b7015d",
   "metadata": {},
   "source": [
    "## Case 3.1: Boolean Data\n",
    "Simple boolean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8217a7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean=['preapproval', 'construction_method']\n",
    "for feature in boolean:\n",
    "    print(\"Number of NaNs:\", df_cleaned[feature].isna().sum())\n",
    "    print(df_cleaned[feature].value_counts().head(5))\n",
    "for feature in boolean:\n",
    "    df_cleaned[feature]=df_cleaned[feature].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65847766",
   "metadata": {},
   "source": [
    "## Case 3.2: Boolean With Exempt\n",
    "The 1111 datafield is equivalent to the Exempt keyword in other columns, so can be treated as equivalent to NA. However, the entry 3 indicates that the loan is not a manufactured-home loan, so this field does not apply. There are clearly no np.nan values, all have been converted to 1111 already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1568582e",
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean_with_exempt=['reverse_mortgage', 'open_end_line_of_credit', 'business_or_commercial_purpose', 'negative_amortization', 'interest_only_payment', 'balloon_payment', 'other_nonamortizing_features']\n",
    "for feature in boolean_with_exempt:\n",
    "    print(\"Number of NaNs:\", df_cleaned[feature].isna().sum())\n",
    "    print(df_cleaned[feature].value_counts().head(200))\n",
    "    df_cleaned[feature]=df_cleaned[feature].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffef5762",
   "metadata": {},
   "outputs": [],
   "source": [
    "#categoricals=list(set(categoricals+boolean+boolean_with_exempt))\n",
    "categoricals=list(set(categoricals+boolean+boolean_with_exempt)-set(high_dim_cat)) # need to figure out how to deal with high dim categoricals\n",
    "features=categoricals\n",
    "df_cleaned=df_cleaned[features+[target]]\n",
    "print(f\"As a double check to make sure we have not left any features, take the set difference of columns and the set sum of feature categories: {set(df_cleaned.columns)-set(features)}. This is the target variable as expected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e0a8eb",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8a34e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_cleaned.reset_index(drop=True)\n",
    "df_cleaned.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa55a014",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode Categoricals\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "categorical_columns=categoricals\n",
    "categorical_dims={col: len(df_cleaned[col].value_counts()) for col in categorical_columns}\n",
    "cat_idxs = [ i for i, f in enumerate(features) if f in categorical_columns]\n",
    "cat_dims = [ categorical_dims[f] for i, f in enumerate(features) if f in categorical_columns]\n",
    "j=[]\n",
    "for col in categorical_columns:\n",
    "    l_enc = LabelEncoder()\n",
    "    df_cleaned[col]=l_enc.fit_transform(df_cleaned[col].values)\n",
    "print(cat_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1906e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_features=None\n",
    "#grouped_features = [[0, 1, 2], [8, 9, 10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64e0c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed_value):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "    \n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        \n",
    "seed_everything(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df249f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Test Split\n",
    "if \"trainingset\" not in df_cleaned.columns:\n",
    "    df_cleaned[\"trainingset\"] = np.random.choice([\"train\", \"valid\", \"test\"], p =[.8, .1, .1], size=(df_cleaned.shape[0],))\n",
    "train_indices = df_cleaned[df_cleaned['trainingset']==\"train\"].index\n",
    "valid_indices = df_cleaned[df_cleaned['trainingset']==\"valid\"].index\n",
    "test_indices = df_cleaned[df_cleaned['trainingset']==\"test\"].index\n",
    "X_train = df_cleaned[features].values[train_indices]\n",
    "y_train = df_cleaned[target].values[train_indices]\n",
    "\n",
    "X_valid = df_cleaned[features].values[valid_indices]\n",
    "y_valid = df_cleaned[target].values[valid_indices]\n",
    "\n",
    "X_test = df_cleaned[features].values[test_indices]\n",
    "y_test = df_cleaned[target].values[test_indices]\n",
    "\n",
    "for col in categorical_columns:\n",
    "    train_vals = set(df_cleaned.loc[train_indices, col].dropna().unique())\n",
    "    test_vals  = set(df_cleaned.loc[test_indices,  col].dropna().unique())\n",
    "\n",
    "    unseen = test_vals - train_vals\n",
    "    if unseen:\n",
    "        print(f\"Unseen categories in test for {col}: {unseen}\")\n",
    "    else:\n",
    "        print(f\"✓ {col}: all good\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528fa974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "neg=len(df_cleaned[df_cleaned['action_taken']==0])/len(df_cleaned)\n",
    "weights=[neg, 1-neg]\n",
    "print(weights)\n",
    "class_weights = torch.tensor([1/weights[0], 1/weights[1]])\n",
    "def Weighted_CE(input, target):\n",
    "    return F.cross_entropy(input, target, weight=class_weights)\n",
    "\n",
    "def Weighted_CE_per_batch(input, target):\n",
    "    \"\"\"\n",
    "    input: logits [batch_size, 2]\n",
    "    target: class indices [batch_size]\n",
    "    \"\"\"\n",
    "    batch_size = target.size(0)\n",
    "    num_class0 = (target == 0).sum().item()\n",
    "    num_class1 = (target == 1).sum().item()\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    num_class0 = max(num_class0, 1)\n",
    "    num_class1 = max(num_class1, 1)\n",
    "    \n",
    "    # Class weights inversely proportional to frequency in this batch\n",
    "    weight = torch.tensor([batch_size/num_class0, batch_size/num_class1], dtype=torch.float, device=input.device)\n",
    "    \n",
    "    # Compute CE with these per-batch weights\n",
    "    return F.cross_entropy(input, target, weight=weight, reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0a53fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabnet_classifier_params={\n",
    "                'n_d': 64,\n",
    "                'n_a': 64,\n",
    "                'n_steps': 5,\n",
    "                \n",
    "                \"cat_idxs\":cat_idxs,\n",
    "                \"cat_dims\":cat_dims,\n",
    "                \"cat_emb_dim\":[j//2 for j in cat_dims],\n",
    "                \"optimizer_fn\":torch.optim.Adam,\n",
    "                \"optimizer_params\":dict(lr=2e-2, weight_decay=1e-5),\n",
    "                \"scheduler_params\":{\"step_size\":50, # how to use learning rate scheduler\n",
    "                                 \"gamma\":0.5},\n",
    "                \"scheduler_fn\":torch.optim.lr_scheduler.StepLR,\n",
    "                \"mask_type\":'entmax', # \"sparsemax\"\n",
    "                #\"grouped_features\" : \n",
    "                }\n",
    "\n",
    "model=TabNetClassifier(**tabnet_classifier_params)\n",
    "model.fit(\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "    eval_name=['train', 'valid'],\n",
    "    eval_metric=['auc', 'accuracy', 'balanced_accuracy', 'logloss'],\n",
    "    max_epochs=10 ,\n",
    "    patience=50, # please be patient ^^\n",
    "    loss_fn=Weighted_CE_per_batch,\n",
    "    batch_size=1024,\n",
    "    virtual_batch_size=128,\n",
    "    num_workers=1,\n",
    "    drop_last=False,\n",
    "    compute_importance=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7f9e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1️⃣ Loss\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(model.history['loss'], label='Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 2️⃣ AUC\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(model.history['train_auc'], label='Train AUC')\n",
    "plt.plot(model.history['valid_auc'], label='Valid AUC')\n",
    "plt.title('AUC over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('AUC')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 3️⃣ Accuracy\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(model.history['train_accuracy'], label='Train Accuracy')\n",
    "plt.plot(model.history['valid_accuracy'], label='Valid Accuracy')\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22510bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction:\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred=model.predict(X_test)\n",
    "test_acc = accuracy_score(y_pred=y_pred, y_true=y_test)\n",
    "print(f\"FINAL TEST SCORE FOR {filename} : {test_acc}\")\n",
    "saved=model.save_model('test_model')\n",
    "#load by doing model.load_model(saved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e23843e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explanations\n",
    "model.feature_importances_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
